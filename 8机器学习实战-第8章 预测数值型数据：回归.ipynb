{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#预测数值型数据：回归\" data-toc-modified-id=\"预测数值型数据：回归-1\">预测数值型数据：回归</a></span><ul class=\"toc-item\"><li><span><a href=\"#用线性回归找到最佳拟合曲线\" data-toc-modified-id=\"用线性回归找到最佳拟合曲线-1.1\">用线性回归找到最佳拟合曲线</a></span></li><li><span><a href=\"#回归的一般方法\" data-toc-modified-id=\"回归的一般方法-1.2\">回归的一般方法</a></span></li><li><span><a href=\"#线性回归\" data-toc-modified-id=\"线性回归-1.3\">线性回归</a></span></li><li><span><a href=\"#代码实现与注释\" data-toc-modified-id=\"代码实现与注释-1.4\">代码实现与注释</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-计算最佳拟合曲线\" data-toc-modified-id=\"1.-计算最佳拟合曲线-1.4.1\">1. 计算最佳拟合曲线</a></span></li></ul></li><li><span><a href=\"#局部加权线性回归（LWLR）\" data-toc-modified-id=\"局部加权线性回归（LWLR）-1.5\">局部加权线性回归（LWLR）</a></span><ul class=\"toc-item\"><li><span><a href=\"#局部加权线性回归函数\" data-toc-modified-id=\"局部加权线性回归函数-1.5.1\">局部加权线性回归函数</a></span></li><li><span><a href=\"#局部加权线性回归-注意事项\" data-toc-modified-id=\"局部加权线性回归-注意事项-1.5.2\">局部加权线性回归 注意事项</a></span></li></ul></li><li><span><a href=\"#线性回归-&amp;-局部加权线性回归-项目案例\" data-toc-modified-id=\"线性回归-&amp;-局部加权线性回归-项目案例-1.6\">线性回归 &amp; 局部加权线性回归 项目案例</a></span><ul class=\"toc-item\"><li><span><a href=\"#项目概述\" data-toc-modified-id=\"项目概述-1.6.1\">项目概述</a></span></li></ul></li><li><span><a href=\"#缩减系数来-“理解”-数据\" data-toc-modified-id=\"缩减系数来-“理解”-数据-1.7\">缩减系数来 “理解” 数据</a></span></li><li><span><a href=\"#岭回归\" data-toc-modified-id=\"岭回归-1.8\">岭回归</a></span><ul class=\"toc-item\"><li><span><a href=\"#岭回归代码\" data-toc-modified-id=\"岭回归代码-1.8.1\">岭回归代码</a></span></li></ul></li><li><span><a href=\"#lasso\" data-toc-modified-id=\"lasso-1.9\">lasso</a></span></li><li><span><a href=\"#前向逐步回归\" data-toc-modified-id=\"前向逐步回归-1.10\">前向逐步回归</a></span><ul class=\"toc-item\"><li><span><a href=\"#代码\" data-toc-modified-id=\"代码-1.10.1\">代码</a></span></li><li><span><a href=\"#小结\" data-toc-modified-id=\"小结-1.10.2\">小结</a></span></li></ul></li><li><span><a href=\"#权衡偏差和方差\" data-toc-modified-id=\"权衡偏差和方差-1.11\">权衡偏差和方差</a></span><ul class=\"toc-item\"><li><span><a href=\"#项目案例1:-预测乐高玩具套装的价格\" data-toc-modified-id=\"项目案例1:-预测乐高玩具套装的价格-1.11.1\">项目案例1: 预测乐高玩具套装的价格</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测数值型数据：回归\n",
    "**摘要**\n",
    "\n",
    "1.线性回归\n",
    "\n",
    "2.局部加权线性回归\n",
    "\n",
    "3.岭回归和逐步线性回归\n",
    "\n",
    "4.预测鲍鱼年龄和玩具售价代码实现和注释\n",
    "\n",
    "\n",
    "\n",
    "## 用线性回归找到最佳拟合曲线\n",
    "\n",
    "**线性回归**\n",
    "> 优点：结果易于理解，计算上不复杂。  \n",
    "缺点：对非线性的数据拟合不好。    \n",
    "适用于数据类型：数值型和标称型数据。   \n",
    "\n",
    "\n",
    "**回归没特别说明的话等同于线性回归**\n",
    "\n",
    "## 回归的一般方法\n",
    ">收集数据: 采用任意方法收集数据   \n",
    "准备数据: 回归需要数值型数据，标称型数据将被转换成二值型数据   \n",
    "分析数据: 绘出数据的可视化二维图将有助于对数据做出理解和分析，在采用缩减法求得新回归系数之后，可以将新拟合线绘在图上作为对比   \n",
    "训练算法: 找到回归系数    \n",
    "测试算法: 使用 R^2 或者预测值和数据的拟合度，来分析模型的效果   \n",
    "使用算法: 使用回归，可以在给定输入的时候预测出一个数值，这是对分类方法的提升，因为这样可以预测连续型数据而不仅仅是离散的类别标签  \n",
    "\n",
    "\n",
    "## 线性回归  \n",
    "\n",
    "我们给定数据集 $D=\\left\\{ (x_1,y_1),(x_2,y_2),...(x_m,y_m) \\right\\} $，其中$ x_i=(x_{i1},x_{i2},...x_{id}) $，$ y_i\\in R$ .\n",
    "\n",
    "线性回归就是想学得一个线性模型来尽可能地预测真实值，即：\n",
    "$$\n",
    "f(x)=w_1x_1+w_2x_2+...+w_dx_d+d\n",
    "$$\n",
    "写成向量的形式就是：\n",
    "$$\n",
    "f(x)=w^Tx+b\n",
    "$$\n",
    "其中 $w=(w_1;w_2;w_3...w_d)$ ，当我们求得$w$和$d$之后，模型也就确定了。\n",
    "\n",
    "我们如何确定$w$和$b$呢？我们需要给定一个目标函数。一般情况下我们采用均方误差最小化，即：\n",
    "$$\n",
    "(w^*,b^*)=argmin\\sum_{i=1}^{m}{(f(x_i)-y_i)^2}\n",
    "$$\n",
    "为了便于讨论，我们把w和x写成如下形式：\n",
    "$$\n",
    "\\begin{array}{aligh}\n",
    "\\tilde{w}=(w;b)\\\\\n",
    "x_i=(x_{i1},x_{i2},...x_{id},1)\n",
    "\\end{array}\n",
    "$$\n",
    "这样，线性回归模型就可以写为：\n",
    "$$\n",
    "f(x)=\\tilde{w}^T\\cdot x\n",
    "$$\n",
    "那上面均方误差最小化写成向量的形式就等价于：\n",
    "$$\n",
    "\\tilde{w}=argmin(y-X\\tilde{w})^T(y-X\\tilde{w})\n",
    "$$\n",
    "其中，$X$为：\n",
    "$$\n",
    "X=\\left( \\begin{array}{ccc} x_{11} & x_{12} & ...&x_{1d}&1 \\\\ x_{21} & x_{22} & ...&x_{2d}&1 \\\\ ... & ... & ...&...&... \\\\ x_{m1} & x_{m2} & ...&x_{md}&1 \\end{array} \\right)\n",
    "$$\n",
    "令 $E_\\tilde{w}=(y-X\\tilde{w})^T(y-X\\tilde{w})$ ，我们令其对 $\\tilde{w}$ 求导：\n",
    "$$\n",
    "\\frac{dE_{\\tilde{w}}}{d\\tilde{w}}=\\frac{d(y-X\\tilde{w})^T(y-X\\tilde{w})}{d\\tilde{w}}=2X^T(X\\tilde{w}-y)\n",
    "$$\n",
    "这个矩阵求导结果怎么得到的呢？很多地方都只是给了结果。\n",
    "\n",
    "推导这一部分得有一些线性代数的知识，关于机器学习数学方面的内容，后面有时间的话我会系统梳理。这里先给大家简单推导一遍，想要详细了解的同学可以看这篇文章，写得很好：https://zhuanlan.zhihu.com/p/24709748\n",
    "\n",
    "我假设大家已经看了上面的文章，了解了具体的公式。\n",
    "\n",
    "由 $d(XY)=dXY+XdY$ ，得到  \n",
    "$\n",
    "=\\cfrac{d(y-X\\tilde{w})^T(y-X\\tilde{w})}{d\\tilde{w}}\n",
    "$\n",
    "\n",
    "$\n",
    "=(Xd\\tilde{w})^T(y-X\\tilde{w})+(y-X\\tilde{w})^T(Xd\\tilde{w})\n",
    "$\n",
    "\n",
    "再由 $df=tr(\\cfrac{\\alpha f}{\\alpha X}^TdX)$ ，得到   \n",
    "\n",
    "$\n",
    "=tr((Xd\\tilde{w})^T(y-X\\tilde{w})+(y-X\\tilde{w})^T(Xd\\tilde{w}))\n",
    "$    \n",
    "\n",
    "再由 $tr(A\\pm B)=tr(A)\\pm tr(B)$ ，得到   \n",
    "\n",
    "$\n",
    "=tr((Xd\\tilde{w})^T(y-X\\tilde{w}))+tr((y-X\\tilde{w})^T(Xd\\tilde{w}))\n",
    "$\n",
    "\n",
    "因为 $tr(A^T)=tr(A)$ ，所以\n",
    "\n",
    "$\n",
    "=tr(Xd\\tilde{w}(y-X\\tilde{w})^T)+tr((y-X\\tilde{w})^T(Xd\\tilde{w}))\n",
    "$\n",
    "\n",
    "又因为 $tr(AB)=tr(BA)$ ，所以\n",
    "\n",
    "$\n",
    "=tr((y-X\\tilde{w})^TXd\\tilde{w})+tr((y-X\\tilde{w})^T(Xd\\tilde{w}))\n",
    "$\n",
    "\n",
    "$\n",
    "=tr(2(y-X\\tilde{w})^TXd\\tilde{w})\n",
    "$\n",
    "\n",
    "$\n",
    "=tr(\\cfrac{\\alpha f}{\\alpha \\tilde{w}}^Td\\tilde{w})\n",
    "$\n",
    "\n",
    "所以得到：   \n",
    "$\n",
    "\\cfrac{\\alpha f}{\\alpha \\tilde{w}}=2X^T(y-X\\tilde{w})\n",
    "$\n",
    "\n",
    "令上式等于零，得到 $\\tilde{w}$ 最优解的闭式解：\n",
    "$$\n",
    "\\tilde{w}^*=(X^T X)^{-1}X^Ty\n",
    "$$\n",
    "当然上式成立的前提条件是 $X^T X$ 可逆。在得到 $\\tilde{w}^*$ 之后，我们也就可以写出线性回归模型：\n",
    "$$\n",
    "f(x)=(\\tilde{w}^*)^Tx\n",
    "$$\n",
    "以上就是线性回归模型的基本形式。\n",
    "\n",
    "## 代码实现与注释\n",
    "\n",
    "### 1. 计算最佳拟合曲线\n",
    "\n",
    "根据下图中的点，找出该数据的最佳拟合曲线\n",
    "![](./image/第8章回归/1.jpg)\n",
    "\n",
    "\n",
    "数据格式为：\n",
    "```\n",
    "x0          x1          y \n",
    "1.000000\t0.067732\t3.176513\n",
    "1.000000\t0.427810\t3.816464\n",
    "1.000000\t0.995731\t4.550095\n",
    "1.000000\t0.738336\t4.256571\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "# 加载函数，并得到特征矩阵和类别矩阵\n",
    "def loadDataSet(fileName):\n",
    "    \"\"\" 加载数据\n",
    "        解析以tab键分隔的文件中的浮点数\n",
    "    Returns：\n",
    "        dataMat ：  feature 对应的数据集\n",
    "        labelMat ： feature 对应的分类标签，即类别标签\n",
    "\n",
    "    \"\"\"\n",
    "    # 获取样本特征的总数，不算最后的目标变量 \n",
    "    numFeat=len(open(fileName).readline().split('\\t'))-1\n",
    "    dataMat=[];labelMat=[]\n",
    "    fr=open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        # 读取每一行\n",
    "        lineArr=[]\n",
    "        # 删除一行中以tab分隔的数据前后的空白符号\n",
    "        curLine=line.strip().split('\\t')\n",
    "        # i 从0到2，不包括2 \n",
    "        for i in range(numFeat):\n",
    "            # 将数据添加到lineArr List中，每一行数据测试数据组成一个行向量           \n",
    "            lineArr.append(float(curLine[i]))\n",
    "            # 将测试数据的输入数据部分存储到dataMat 的List中\n",
    "        dataMat.append(lineArr)\n",
    "        # 将每一行的最后一个数据，即类别，或者叫目标变量存储到labelMat List中\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "# 计算最佳拟合曲线\n",
    "def standRegress(xArr,yArr):\n",
    "    '''\n",
    "    Description：\n",
    "        线性回归\n",
    "    Args:\n",
    "        xArr ：输入的样本数据，包含每个样本数据的 feature\n",
    "        yArr ：对应于输入数据的类别标签，也就是每个样本对应的目标变量\n",
    "    Returns:\n",
    "        ws：回归系数\n",
    "    '''\n",
    "\n",
    "    # mat()函数将xArr，yArr转换为矩阵 mat().T 代表的是对矩阵进行转置操作\n",
    "    xMat=mat(xArr)\n",
    "    yMat=mat(yArr).T\n",
    "    # 矩阵乘法的条件是左矩阵的列数等于右矩阵的行数\n",
    "    xTx=xMat.T*xMat\n",
    "    # 因为要用到xTx的逆矩阵，所以事先需要确定计算得到的xTx是否可逆，条件是矩阵的行列式不为0\n",
    "    # linalg.det() 函数是用来求得矩阵的行列式的，如果矩阵的行列式为0，则这个矩阵是不可逆的，就无法进行接下来的运算                   \n",
    "    # 如果行列式等于零，则矩阵不可逆，直接返回\n",
    "    if(linalg.det(xTx)==0.0):\n",
    "        print(\"This matrix is singular,cannot do inverse\")\n",
    "        return\n",
    "    # 最小二乘法\n",
    "    # 利用公式计算回归系数\n",
    "    ws=xTx.I*(xMat.T*yMat)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1.0, 0.067732],\n",
       "  [1.0, 0.42781],\n",
       "  [1.0, 0.995731],\n",
       "  [1.0, 0.738336],\n",
       "  [1.0, 0.981083],\n",
       "  [1.0, 0.526171],\n",
       "  [1.0, 0.378887],\n",
       "  [1.0, 0.033859],\n",
       "  [1.0, 0.132791],\n",
       "  [1.0, 0.138306],\n",
       "  [1.0, 0.247809],\n",
       "  [1.0, 0.64827],\n",
       "  [1.0, 0.731209],\n",
       "  [1.0, 0.236833],\n",
       "  [1.0, 0.969788],\n",
       "  [1.0, 0.607492],\n",
       "  [1.0, 0.358622],\n",
       "  [1.0, 0.147846],\n",
       "  [1.0, 0.63782],\n",
       "  [1.0, 0.230372],\n",
       "  [1.0, 0.070237],\n",
       "  [1.0, 0.067154],\n",
       "  [1.0, 0.925577],\n",
       "  [1.0, 0.717733],\n",
       "  [1.0, 0.015371],\n",
       "  [1.0, 0.33507],\n",
       "  [1.0, 0.040486],\n",
       "  [1.0, 0.212575],\n",
       "  [1.0, 0.617218],\n",
       "  [1.0, 0.541196],\n",
       "  [1.0, 0.045353],\n",
       "  [1.0, 0.126762],\n",
       "  [1.0, 0.556486],\n",
       "  [1.0, 0.901144],\n",
       "  [1.0, 0.958476],\n",
       "  [1.0, 0.274561],\n",
       "  [1.0, 0.394396],\n",
       "  [1.0, 0.87248],\n",
       "  [1.0, 0.409932],\n",
       "  [1.0, 0.908969],\n",
       "  [1.0, 0.166819],\n",
       "  [1.0, 0.665016],\n",
       "  [1.0, 0.263727],\n",
       "  [1.0, 0.231214],\n",
       "  [1.0, 0.552928],\n",
       "  [1.0, 0.047744],\n",
       "  [1.0, 0.365746],\n",
       "  [1.0, 0.495002],\n",
       "  [1.0, 0.493466],\n",
       "  [1.0, 0.792101],\n",
       "  [1.0, 0.76966],\n",
       "  [1.0, 0.251821],\n",
       "  [1.0, 0.181951],\n",
       "  [1.0, 0.808177],\n",
       "  [1.0, 0.334116],\n",
       "  [1.0, 0.33863],\n",
       "  [1.0, 0.452584],\n",
       "  [1.0, 0.69477],\n",
       "  [1.0, 0.590902],\n",
       "  [1.0, 0.307928],\n",
       "  [1.0, 0.148364],\n",
       "  [1.0, 0.70218],\n",
       "  [1.0, 0.721544],\n",
       "  [1.0, 0.666886],\n",
       "  [1.0, 0.124931],\n",
       "  [1.0, 0.618286],\n",
       "  [1.0, 0.381086],\n",
       "  [1.0, 0.385643],\n",
       "  [1.0, 0.777175],\n",
       "  [1.0, 0.116089],\n",
       "  [1.0, 0.115487],\n",
       "  [1.0, 0.66351],\n",
       "  [1.0, 0.254884],\n",
       "  [1.0, 0.993888],\n",
       "  [1.0, 0.295434],\n",
       "  [1.0, 0.952523],\n",
       "  [1.0, 0.307047],\n",
       "  [1.0, 0.277261],\n",
       "  [1.0, 0.279101],\n",
       "  [1.0, 0.175724],\n",
       "  [1.0, 0.156383],\n",
       "  [1.0, 0.733165],\n",
       "  [1.0, 0.848142],\n",
       "  [1.0, 0.771184],\n",
       "  [1.0, 0.429492],\n",
       "  [1.0, 0.162176],\n",
       "  [1.0, 0.917064],\n",
       "  [1.0, 0.315044],\n",
       "  [1.0, 0.201473],\n",
       "  [1.0, 0.297038],\n",
       "  [1.0, 0.336647],\n",
       "  [1.0, 0.666109],\n",
       "  [1.0, 0.583888],\n",
       "  [1.0, 0.085031],\n",
       "  [1.0, 0.687006],\n",
       "  [1.0, 0.949655],\n",
       "  [1.0, 0.189912],\n",
       "  [1.0, 0.844027],\n",
       "  [1.0, 0.333288],\n",
       "  [1.0, 0.427035],\n",
       "  [1.0, 0.466369],\n",
       "  [1.0, 0.550659],\n",
       "  [1.0, 0.278213],\n",
       "  [1.0, 0.918769],\n",
       "  [1.0, 0.886555],\n",
       "  [1.0, 0.569488],\n",
       "  [1.0, 0.066379],\n",
       "  [1.0, 0.335751],\n",
       "  [1.0, 0.426863],\n",
       "  [1.0, 0.395746],\n",
       "  [1.0, 0.694221],\n",
       "  [1.0, 0.27276],\n",
       "  [1.0, 0.503495],\n",
       "  [1.0, 0.067119],\n",
       "  [1.0, 0.038326],\n",
       "  [1.0, 0.599122],\n",
       "  [1.0, 0.947054],\n",
       "  [1.0, 0.671279],\n",
       "  [1.0, 0.434811],\n",
       "  [1.0, 0.509381],\n",
       "  [1.0, 0.749442],\n",
       "  [1.0, 0.058014],\n",
       "  [1.0, 0.482978],\n",
       "  [1.0, 0.466776],\n",
       "  [1.0, 0.357767],\n",
       "  [1.0, 0.949123],\n",
       "  [1.0, 0.41732],\n",
       "  [1.0, 0.920461],\n",
       "  [1.0, 0.156433],\n",
       "  [1.0, 0.656662],\n",
       "  [1.0, 0.616418],\n",
       "  [1.0, 0.853428],\n",
       "  [1.0, 0.133295],\n",
       "  [1.0, 0.693007],\n",
       "  [1.0, 0.178449],\n",
       "  [1.0, 0.199526],\n",
       "  [1.0, 0.073224],\n",
       "  [1.0, 0.286515],\n",
       "  [1.0, 0.182026],\n",
       "  [1.0, 0.621523],\n",
       "  [1.0, 0.344584],\n",
       "  [1.0, 0.398556],\n",
       "  [1.0, 0.480369],\n",
       "  [1.0, 0.15335],\n",
       "  [1.0, 0.171846],\n",
       "  [1.0, 0.867082],\n",
       "  [1.0, 0.223855],\n",
       "  [1.0, 0.528301],\n",
       "  [1.0, 0.890192],\n",
       "  [1.0, 0.106352],\n",
       "  [1.0, 0.917886],\n",
       "  [1.0, 0.014855],\n",
       "  [1.0, 0.567682],\n",
       "  [1.0, 0.068854],\n",
       "  [1.0, 0.603535],\n",
       "  [1.0, 0.53205],\n",
       "  [1.0, 0.651362],\n",
       "  [1.0, 0.901225],\n",
       "  [1.0, 0.204337],\n",
       "  [1.0, 0.696081],\n",
       "  [1.0, 0.963924],\n",
       "  [1.0, 0.98139],\n",
       "  [1.0, 0.987911],\n",
       "  [1.0, 0.990947],\n",
       "  [1.0, 0.736021],\n",
       "  [1.0, 0.253574],\n",
       "  [1.0, 0.674722],\n",
       "  [1.0, 0.939368],\n",
       "  [1.0, 0.235419],\n",
       "  [1.0, 0.110521],\n",
       "  [1.0, 0.218023],\n",
       "  [1.0, 0.869778],\n",
       "  [1.0, 0.19683],\n",
       "  [1.0, 0.958178],\n",
       "  [1.0, 0.972673],\n",
       "  [1.0, 0.745797],\n",
       "  [1.0, 0.445674],\n",
       "  [1.0, 0.470557],\n",
       "  [1.0, 0.549236],\n",
       "  [1.0, 0.335691],\n",
       "  [1.0, 0.884739],\n",
       "  [1.0, 0.918916],\n",
       "  [1.0, 0.441815],\n",
       "  [1.0, 0.116598],\n",
       "  [1.0, 0.359274],\n",
       "  [1.0, 0.814811],\n",
       "  [1.0, 0.387125],\n",
       "  [1.0, 0.982243],\n",
       "  [1.0, 0.78088],\n",
       "  [1.0, 0.652565],\n",
       "  [1.0, 0.87003],\n",
       "  [1.0, 0.604755],\n",
       "  [1.0, 0.255212],\n",
       "  [1.0, 0.730546],\n",
       "  [1.0, 0.493829],\n",
       "  [1.0, 0.257017],\n",
       "  [1.0, 0.833735],\n",
       "  [1.0, 0.070095],\n",
       "  [1.0, 0.52707],\n",
       "  [1.0, 0.116163]],\n",
       " [3.176513,\n",
       "  3.816464,\n",
       "  4.550095,\n",
       "  4.256571,\n",
       "  4.560815,\n",
       "  3.929515,\n",
       "  3.52617,\n",
       "  3.156393,\n",
       "  3.110301,\n",
       "  3.149813,\n",
       "  3.476346,\n",
       "  4.119688,\n",
       "  4.282233,\n",
       "  3.486582,\n",
       "  4.655492,\n",
       "  3.965162,\n",
       "  3.5149,\n",
       "  3.125947,\n",
       "  4.094115,\n",
       "  3.476039,\n",
       "  3.21061,\n",
       "  3.190612,\n",
       "  4.631504,\n",
       "  4.29589,\n",
       "  3.085028,\n",
       "  3.44808,\n",
       "  3.16744,\n",
       "  3.364266,\n",
       "  3.993482,\n",
       "  3.891471,\n",
       "  3.143259,\n",
       "  3.114204,\n",
       "  3.851484,\n",
       "  4.621899,\n",
       "  4.580768,\n",
       "  3.620992,\n",
       "  3.580501,\n",
       "  4.618706,\n",
       "  3.676867,\n",
       "  4.641845,\n",
       "  3.175939,\n",
       "  4.26498,\n",
       "  3.558448,\n",
       "  3.436632,\n",
       "  3.831052,\n",
       "  3.182853,\n",
       "  3.498906,\n",
       "  3.946833,\n",
       "  3.900583,\n",
       "  4.238522,\n",
       "  4.23308,\n",
       "  3.521557,\n",
       "  3.203344,\n",
       "  4.278105,\n",
       "  3.555705,\n",
       "  3.502661,\n",
       "  3.859776,\n",
       "  4.275956,\n",
       "  3.916191,\n",
       "  3.587961,\n",
       "  3.183004,\n",
       "  4.225236,\n",
       "  4.231083,\n",
       "  4.240544,\n",
       "  3.222372,\n",
       "  4.021445,\n",
       "  3.567479,\n",
       "  3.56258,\n",
       "  4.262059,\n",
       "  3.208813,\n",
       "  3.169825,\n",
       "  4.193949,\n",
       "  3.491678,\n",
       "  4.533306,\n",
       "  3.550108,\n",
       "  4.636427,\n",
       "  3.557078,\n",
       "  3.552874,\n",
       "  3.494159,\n",
       "  3.206828,\n",
       "  3.195266,\n",
       "  4.221292,\n",
       "  4.413372,\n",
       "  4.184347,\n",
       "  3.742878,\n",
       "  3.201878,\n",
       "  4.648964,\n",
       "  3.510117,\n",
       "  3.274434,\n",
       "  3.579622,\n",
       "  3.489244,\n",
       "  4.237386,\n",
       "  3.913749,\n",
       "  3.22899,\n",
       "  4.286286,\n",
       "  4.628614,\n",
       "  3.239536,\n",
       "  4.457997,\n",
       "  3.513384,\n",
       "  3.729674,\n",
       "  3.834274,\n",
       "  3.811155,\n",
       "  3.598316,\n",
       "  4.692514,\n",
       "  4.604859,\n",
       "  3.864912,\n",
       "  3.184236,\n",
       "  3.500796,\n",
       "  3.743365,\n",
       "  3.622905,\n",
       "  4.310796,\n",
       "  3.583357,\n",
       "  3.901852,\n",
       "  3.233521,\n",
       "  3.105266,\n",
       "  3.865544,\n",
       "  4.628625,\n",
       "  4.231213,\n",
       "  3.791149,\n",
       "  3.968271,\n",
       "  4.25391,\n",
       "  3.19471,\n",
       "  3.996503,\n",
       "  3.904358,\n",
       "  3.503976,\n",
       "  4.557545,\n",
       "  3.699876,\n",
       "  4.613614,\n",
       "  3.140401,\n",
       "  4.206717,\n",
       "  3.969524,\n",
       "  4.476096,\n",
       "  3.136528,\n",
       "  4.279071,\n",
       "  3.200603,\n",
       "  3.299012,\n",
       "  3.209873,\n",
       "  3.632942,\n",
       "  3.248361,\n",
       "  3.995783,\n",
       "  3.563262,\n",
       "  3.649712,\n",
       "  3.951845,\n",
       "  3.145031,\n",
       "  3.181577,\n",
       "  4.637087,\n",
       "  3.404964,\n",
       "  3.873188,\n",
       "  4.633648,\n",
       "  3.154768,\n",
       "  4.623637,\n",
       "  3.078132,\n",
       "  3.913596,\n",
       "  3.221817,\n",
       "  3.938071,\n",
       "  3.880822,\n",
       "  4.176436,\n",
       "  4.648161,\n",
       "  3.332312,\n",
       "  4.240614,\n",
       "  4.532224,\n",
       "  4.557105,\n",
       "  4.610072,\n",
       "  4.636569,\n",
       "  4.229813,\n",
       "  3.50086,\n",
       "  4.245514,\n",
       "  4.605182,\n",
       "  3.45434,\n",
       "  3.180775,\n",
       "  3.38082,\n",
       "  4.56502,\n",
       "  3.279973,\n",
       "  4.554241,\n",
       "  4.63352,\n",
       "  4.281037,\n",
       "  3.844426,\n",
       "  3.891601,\n",
       "  3.849728,\n",
       "  3.492215,\n",
       "  4.592374,\n",
       "  4.632025,\n",
       "  3.75675,\n",
       "  3.133555,\n",
       "  3.567919,\n",
       "  4.363382,\n",
       "  3.560165,\n",
       "  4.564305,\n",
       "  4.215055,\n",
       "  4.174999,\n",
       "  4.58664,\n",
       "  3.960008,\n",
       "  3.529963,\n",
       "  4.213412,\n",
       "  3.908685,\n",
       "  3.585821,\n",
       "  4.374394,\n",
       "  3.213817,\n",
       "  3.952681,\n",
       "  3.129283])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xArr,yArr=loadDataSet(\"./input&code/Ch08/ex0.txt\")\n",
    "xArr,yArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.00774324],\n",
       "        [1.69532264]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws=standRegress(xArr,yArr)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xMat=mat(xArr)\n",
    "yMat=mat(yArr)\n",
    "yHat=xMat*ws\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "ax.scatter(xMat[:,1].flatten().A[0],yMat.T[:,0].flatten().A[0])\n",
    "xCopy = xMat.copy()\n",
    "xCopy.sort(0)\n",
    "yHat = xCopy *ws\n",
    "ax.plot(xCopy[:,1],yHat,'red') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.98647356]\n",
      " [0.98647356 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "yHat=xMat*ws\n",
    "print (corrcoef(yHat.T, yMat))#计算相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 局部加权线性回归（LWLR）\n",
    "\n",
    "　　局部加权线性回归的原理很简单：当出现一个新的样本需要预测，我在训练回归系数 $w$ 时，并不是给所有训练样本同样的权重，而是距离新样本近的训练样本权重大，距离新样本远的训练样本权重小，这样可以对新样本进行更准确的预测。因为我们更看重训练样本局部的趋势。\n",
    "\n",
    "算法解出回归系数的公式如下：\n",
    "$$\n",
    "w=(X^TWX)X^TWy\n",
    "$$\n",
    "这里的$W$就是每个训练样本的权重。\n",
    "线性回归的一个问题是有可能出现欠拟合现象，因为它求的是具有最小均方差的无偏估计。显而易见，如果模型欠拟合将不能取得最好的预测效果。所以有些方法允许在估计中引入一些偏差，从而降低预测的均方误差。\n",
    "\n",
    "一个方法是局部加权线性回归（Locally Weighted Linear Regression，LWLR）。在这个算法中，我们给预测点附近的每个点赋予一定的权重，然后与 线性回归 类似，在这个子集上基于最小均方误差来进行普通的回归。我们需要最小化的目标函数大致为:\n",
    "$$\n",
    "\\sum_i w(y^{(i)} - \\hat y ^{(i)})^2\n",
    "$$\n",
    "\n",
    "与 kNN 一样，这种算法每次预测均需要事先选取出对应的数据子集。该算法解出回归系数 $w$ 的形式如下:\n",
    "\n",
    "$$\n",
    "w(i,i)=exp\\left ( \\cfrac {\\mid x^{(i)}-x \\mid}{-2k^2}\\right )\n",
    "$$\n",
    "\n",
    "\n",
    "这样就构建了一个只含对角元素的权重矩阵$ w$，并且点 $x$ 与$ x(i)$ 越近，$w(i, i)$ 将会越大。上述公式中包含一个需要用户指定的参数 k，它决定了对附近的点赋予多大的权重，这也是使用 LWLR 时唯一需要考虑的参数，下面的图给出了参数 $k$ 与权重的关系。\n",
    "\n",
    "![](./image/第8章回归/2.jpg)\n",
    "\n",
    "上面的图是 每个点的权重图（假定我们正预测的点是 x = 0.5），最上面的图是原始数据集，第二个图显示了当 k = 0.5 时，大部分的数据都用于训练回归模型；而最下面的图显示当 k=0.01 时，仅有很少的局部点被用于训练回归模型。\n",
    "\n",
    "### 局部加权线性回归函数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 局部加权线性回归\n",
    "def lwlr(testPoint,xArr,yArr,k=1.0):\n",
    "    '''\n",
    "        Description：\n",
    "            局部加权线性回归，在待预测点附近的每个点赋予一定的权重，在子集上基于最小均方差来进行普通的回归。\n",
    "        Args：\n",
    "            testPoint：样本点\n",
    "            xArr：样本的特征数据，即 feature\n",
    "            yArr：每个样本对应的类别标签，即目标变量\n",
    "            k:关于赋予权重矩阵的核的一个参数，与权重的衰减速率有关\n",
    "        Returns:\n",
    "            testPoint * ws：数据点与具有权重的系数相乘得到的预测点\n",
    "        Notes:\n",
    "            这其中会用到计算权重的公式，w = e^((x^((i))-x) / -2k^2)\n",
    "            理解：x为某个预测点，x^((i))为样本点，样本点距离预测点越近，贡献的误差越大（权值越大），越远则贡献的误差越小（权值越小）。\n",
    "            关于预测点的选取，在我的代码中取的是样本点。其中k是带宽参数，控制w（钟形函数）的宽窄程度，类似于高斯函数的标准差。\n",
    "            算法思路：假设预测点取样本点中的第i个样本点（共m个样本点），遍历1到m个样本点（含第i个），算出每一个样本点与预测点的距离，\n",
    "            也就可以计算出每个样本贡献误差的权值，可以看出w是一个有m个元素的向量（写成对角阵形式）。\n",
    "    '''\n",
    "    # mat() 函数是将array转换为矩阵的函数， mat().T 是转换为矩阵之后，再进行转置操作\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    # 获得xMat矩阵的行数\n",
    "    m = shape(xMat)[0]\n",
    "    # eye()返回一个对角线元素为1，其他元素为0的二维数组，创建权重矩阵weights，该矩阵为每个样本点初始化了一个权重                   \n",
    "    weights = mat(eye((m)))\n",
    "    for j in range(m):\n",
    "        # testPoint 的形式是 一个行向量的形式\n",
    "        # 计算 testPoint 与输入样本点之间的距离，然后下面计算出每个样本贡献误差的权值\n",
    "        diffMat = testPoint - xMat[j,:]\n",
    "        # k控制衰减的速度\n",
    "        weights[j,j] = exp(diffMat*diffMat.T/(-2.0*k**2))\n",
    "    # 根据矩阵乘法计算 xTx ，其中的 weights 矩阵是样本点对应的权重矩阵\n",
    "    xTx = xMat.T * (weights * xMat)\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        print (\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    # 计算出回归系数的一个估计\n",
    "    ws = xTx.I * (xMat.T * (weights * yMat))\n",
    "    return testPoint * ws\n",
    "\n",
    "def lwlrTest(testArr,xArr,yArr,k=1.0):\n",
    "    '''\n",
    "        Description：\n",
    "            测试局部加权线性回归，对数据集中每个点调用 lwlr() 函数\n",
    "        Args：\n",
    "            testArr：测试所用的所有样本点\n",
    "            xArr：样本的特征数据，即 feature\n",
    "            yArr：每个样本对应的类别标签，即目标变量\n",
    "            k：控制核函数的衰减速率\n",
    "        Returns：\n",
    "            yHat：预测点的估计值\n",
    "    '''\n",
    "    # 得到样本点的总数\n",
    "    m = shape(testArr)[0]\n",
    "    # 构建一个全部都是 0 的 1 * m 的矩阵\n",
    "    yHat = zeros(m)\n",
    "    # 循环所有的数据点，并将lwlr运用于所有的数据点 \n",
    "    for i in range(m):\n",
    "        yHat[i] = lwlr(testArr[i],xArr,yArr,k)\n",
    "    # 返回估计值\n",
    "    return yHat\n",
    "\n",
    "def lwlrTestPlot(xArr,yArr,k=1.0):  \n",
    "    '''\n",
    "        Description:\n",
    "            首先将 X 排序，其余的都与lwlrTest相同，这样更容易绘图\n",
    "        Args：\n",
    "            xArr：样本的特征数据，即 feature\n",
    "            yArr：每个样本对应的类别标签，即目标变量，实际值\n",
    "            k：控制核函数的衰减速率的有关参数，这里设定的是常量值 1\n",
    "        Return：\n",
    "            yHat：样本点的估计值\n",
    "            xCopy：xArr的复制\n",
    "    '''\n",
    "    # 生成一个与目标变量数目相同的 0 向量\n",
    "    yHat = zeros(shape(yArr))\n",
    "    # 将 xArr 转换为 矩阵形式\n",
    "    xCopy = mat(xArr)\n",
    "    # 排序\n",
    "    xCopy.sort(0)\n",
    "    # 开始循环，为每个样本点进行局部加权线性回归，得到最终的目标变量估计值\n",
    "    for i in range(shape(xArr)[0]):\n",
    "        yHat[i] = lwlr(xCopy[i],xArr,yArr,k)\n",
    "    return yHat,xCopy\n",
    "\n",
    "\n",
    "#test for LWLR\n",
    "def regression2():\n",
    "    xArr, yArr = loadDataSet(\"./input&code/Ch08/ex0.txt\")\n",
    "    yHat = lwlrTest(xArr, xArr, yArr, 0.003)\n",
    "    xMat = mat(xArr)\n",
    "    srtInd = xMat[:,1].argsort(0)           #argsort()函数是将x中的元素从小到大排列，提取其对应的index(索引)，然后输出\n",
    "    xSort=xMat[srtInd][:,0,:]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(xSort[:,1], yHat[srtInd])\n",
    "    ax.scatter(xMat[:,1].flatten().A[0], mat(yArr).T.flatten().A[0] , s=2, c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/第8章回归/3.jpg)\n",
    "\n",
    "上图使用了 3 种不同平滑值绘出的局部加权线性回归的结果。上图中的平滑系数 k =1.0，中图 k = 0.01，下图 k = 0.003 。可以看到，k = 1.0 时的模型效果与最小二乘法差不多，k=0.01时该模型可以挖出数据的潜在规律，而 k=0.003时则考虑了太多的噪声，进而导致了过拟合现象。\n",
    "\n",
    "### 局部加权线性回归 注意事项\n",
    "局部加权线性回归也存在一个问题，即增加了计算量，因为它对每个点做预测时都必须使用整个数据集。\n",
    "\n",
    "## 线性回归 & 局部加权线性回归 项目案例\n",
    "\n",
    "到此为止，我们已经介绍了找出最佳拟合直线的两种方法，下面我们用这些技术来预测鲍鱼的年龄。\n",
    "\n",
    "### 项目概述\n",
    "我们有一份来自 UCI 的数据集合的数据，记录了鲍鱼（一种介壳类水生动物）的年龄。鲍鱼年龄可以从鲍鱼壳的层数推算得到。\n",
    "\n",
    "\n",
    "数据存储格式：\n",
    "```\n",
    "1\t0.455\t0.365\t0.095\t0.514\t0.2245\t0.101\t0.15\t15\n",
    "1\t0.35\t0.265\t0.09\t0.2255\t0.0995\t0.0485\t0.07\t7\n",
    "-1\t0.53\t0.42\t0.135\t0.677\t0.2565\t0.1415\t0.21\t9\n",
    "1\t0.44\t0.365\t0.125\t0.516\t0.2155\t0.114\t0.155\t10\n",
    "0\t0.33\t0.255\t0.08\t0.205\t0.0895\t0.0395\t0.055\t7\n",
    "```\n",
    "\n",
    "使用上面我们讲到的 局部加权线性回归 训练算法，求出回归系数\n",
    "\n",
    ">测试算法: 使用 rssError()函数 计算预测误差的大小，来分析模型的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rssError(yArr,yHatArr):\n",
    "    return ((yArr-yHatArr)**2).sum()\n",
    "\n",
    "# test for abloneDataSet\n",
    "def abaloneTest():\n",
    "    '''\n",
    "    Desc:\n",
    "        预测鲍鱼的年龄\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # 加载数据\n",
    "    abX, abY = loadDataSet(\"./input&code/Ch08/abalone.txt\")\n",
    "    # 使用不同的核进行预测\n",
    "    oldyHat01 = lwlrTest(abX[0:99], abX[0:99], abY[0:99], 0.1)\n",
    "    oldyHat1 = lwlrTest(abX[0:99], abX[0:99], abY[0:99], 1)\n",
    "    oldyHat10 = lwlrTest(abX[0:99], abX[0:99], abY[0:99], 10)   \n",
    "    # 打印出不同的核预测值与训练数据集上的真实值之间的误差大小\n",
    "    print(\"old yHat01 error Size is :\" , rssError(abY[0:99], oldyHat01.T))\n",
    "    print(\"old yHat1 error Size is :\" , rssError(abY[0:99], oldyHat1.T))\n",
    "    print(\"old yHat10 error Size is :\" , rssError(abY[0:99], oldyHat10.T))\n",
    "\n",
    "    # 打印出 不同的核预测值 与 新数据集（测试数据集）上的真实值之间的误差大小\n",
    "    newyHat01 = lwlrTest(abX[100:199], abX[0:99], abY[0:99], 0.1)\n",
    "    print (\"new yHat01 error Size is :\" , rssError(abY[0:99], newyHat01.T))\n",
    "    newyHat1 = lwlrTest(abX[100:199], abX[0:99], abY[0:99], 1)\n",
    "    print (\"new yHat1 error Size is :\" , rssError(abY[0:99], newyHat1.T))\n",
    "    newyHat10 = lwlrTest(abX[100:199], abX[0:99], abY[0:99], 10)\n",
    "    print (\"new yHat10 error Size is :\" , rssError(abY[0:99], newyHat10.T))\n",
    "\n",
    "    # 使用简单的 线性回归 进行预测，与上面的计算进行比较\n",
    "    standWs = standRegress(abX[0:99], abY[0:99])\n",
    "    standyHat = mat(abX[100:199]) * standWs\n",
    "    print(\"standRegress error Size is:\", rssError(abY[100:199], standyHat.T.A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old yHat01 error Size is : 56.78868743050092\n",
      "old yHat1 error Size is : 429.89056187038\n",
      "old yHat10 error Size is : 549.1181708827924\n",
      "new yHat01 error Size is : 62452.59620515083\n",
      "new yHat1 error Size is : 3207.689628823445\n",
      "new yHat10 error Size is : 3320.08921090694\n",
      "standRegress error Size is: 518.6363153245542\n"
     ]
    }
   ],
   "source": [
    "abaloneTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单线性回归达到了与局部加权现行回归类似的效果。这也说明了一点，必须在未知数据上比较效果才能选取到最佳模型。那么最佳的核大小是 10 吗？或许是，但如果想得到更好的效果，应该用 10 个不同的样本集做 10 次测试来比较结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缩减系数来 “理解” 数据\n",
    "\n",
    "如果数据的特征比样本点还多应该怎么办？是否还可以使用线性回归和之前的方法来做预测？答案是否定的，即我们不能再使用前面介绍的方法。这是因为在计算$(x^T x)^{-1}$的时候会出错。\n",
    "\n",
    "如果特征比样本点还多(n > m)，也就是说输入数据的矩阵$ x$ 不是满秩矩阵。非满秩矩阵求逆时会出现问题。\n",
    "\n",
    "为了解决这个问题，我们引入了 岭回归（ridge regression） 这种缩减方法。接着是 lasso法，最后介绍 前向逐步回归。\n",
    "\n",
    "## 岭回归\n",
    "\n",
    "简单来说，岭回归就是在矩阵$x^T x$上加一个 $\\lambda I$ 从而使得矩阵非奇异，进而能对$x^T x+\\lambda I$求逆。其中矩阵I是一个$ m * m$ 的单位矩阵， 对角线上元素全为1，其他元素全为0。而λ是一个用户定义的数值，后面会做介绍。在这种情况下，回归系数的计算公式将变成：\n",
    "$$\n",
    "\\hat w=(X^T X+\\lambda I)^{-1}X^T y\n",
    "$$\n",
    "\n",
    "岭回归最先用来处理特征数多于样本数的情况，现在也用于在估计中加入偏差，从而得到更好的估计。这里通过引入 $\\lambda$ 来限制了所有$w$ 之和，通过引入该惩罚项，能够减少不重要的参数，这个技术在统计学中也叫作 缩减(shrinkage)。\n",
    "\n",
    "* 岭回归的岭是什么\n",
    ">岭回归使用了单位矩阵乘以产量$\\lambda$。我们观察其中单位矩阵$I$，可以看到I贯穿整个对角线，其余元素全是0，形象地，在0构成的平面上有一条I组成的“岭”。\n",
    "\n",
    "![](./image/第8章回归/4.jpg)\n",
    "\n",
    "缩减方法可以去掉不重要的参数，因此能更好地理解数据。此外，与简单的线性回归相比，缩减法能取得更好的预测效果。\n",
    "\n",
    "这里通过预测误差最小化得到 λ: 数据获取之后，首先抽一部分数据用于测试，剩余的作为训练集用于训练参数 w。训练完毕后在测试集上测试预测性能。通过选取不同的 λ 来重复上述测试过程，最终得到一个使预测误差最小的 λ 。\n",
    "\n",
    "### 岭回归代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeRegres(xMat,yMat,lam=0.2):\n",
    "    '''\n",
    "        Desc：\n",
    "            这个函数实现了给定 lambda 下的岭回归求解。\n",
    "            如果数据的特征比样本点还多，就不能再使用上面介绍的的线性回归和局部现行回归了，因为计算 (xTx)^(-1)会出现错误。\n",
    "            如果特征比样本点还多（n > m），也就是说，输入数据的矩阵x不是满秩矩阵。非满秩矩阵在求逆时会出现问题。\n",
    "            为了解决这个问题，我们下边讲一下：岭回归，这是我们要讲的第一种缩减方法。\n",
    "        Args：\n",
    "            xMat：样本的特征数据，即 feature\n",
    "            yMat：每个样本对应的类别标签，即目标变量，实际值\n",
    "            lam：引入的一个λ值，使得矩阵非奇异\n",
    "        Returns：\n",
    "            经过岭回归公式计算得到的回归系数\n",
    "    '''\n",
    "\n",
    "    xTx = xMat.T*xMat\n",
    "    # 岭回归就是在矩阵 xTx 上加一个 λI 从而使得矩阵非奇异，进而能对 xTx + λI 求逆\n",
    "    denom = xTx + eye(shape(xMat)[1])*lam\n",
    "    # 检查行列式是否为零，即矩阵是否可逆，行列式为0的话就不可逆，不为0的话就是可逆。\n",
    "    if linalg.det(denom) == 0.0:\n",
    "        print (\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = denom.I * (xMat.T*yMat)\n",
    "    return ws\n",
    "\n",
    "\n",
    "def ridgeTest(xArr,yArr):\n",
    "    '''\n",
    "        Desc：\n",
    "            函数 ridgeTest() 用于在一组 λ 上测试结果\n",
    "        Args：\n",
    "            xArr：样本数据的特征，即 feature\n",
    "            yArr：样本数据的类别标签，即真实数据\n",
    "        Returns：\n",
    "            wMat：将所有的回归系数输出到一个矩阵并返回\n",
    "    '''\n",
    "\n",
    "    xMat = mat(xArr)\n",
    "    yMat=mat(yArr).T\n",
    "    # 计算Y的均值\n",
    "    yMean = mean(yMat,0)\n",
    "    # Y的所有的特征减去均值\n",
    "    yMat = yMat - yMean\n",
    "    # 标准化 x，计算 xMat 平均值\n",
    "    xMeans = mean(xMat,0)\n",
    "    # 然后计算 X的方差\n",
    "    xVar = var(xMat,0)\n",
    "    # 所有特征都减去各自的均值并除以方差\n",
    "    xMat = (xMat - xMeans)/xVar\n",
    "    # 可以在 30 个不同的 lambda 下调用 ridgeRegres() 函数。\n",
    "    numTestPts = 30\n",
    "    # 创建30 * m 的全部数据为0 的矩阵\n",
    "    wMat = zeros((numTestPts,shape(xMat)[1]))\n",
    "    for i in range(numTestPts):\n",
    "        # exp() 返回 e^x \n",
    "        ws = ridgeRegres(xMat,yMat,exp(i-10))\n",
    "        wMat[i,:]=ws.T\n",
    "    return wMat\n",
    "\n",
    "\n",
    "#test for ridgeRegression\n",
    "def regression3():\n",
    "    abX,abY = loadDataSet(\"./input&code/Ch08/abalone.txt\")\n",
    "    ridgeWeights = ridgeTest(abX, abY)    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(ridgeWeights)\n",
    "    plt.xlabel('log(lambda)')\n",
    "    plt.show()\n",
    "    crossValidation(abX,abY,10)\n",
    "    \n",
    "    \n",
    "# 交叉验证测试岭回归\n",
    "# numVal是交叉验证的次数\n",
    "def crossValidation(xArr,yArr,numVal=10):\n",
    "    m = len(yArr)                           \n",
    "    indexList = list(range(m))\n",
    "    errorMat = zeros((numVal,30))#create error mat 30columns numVal rows\n",
    "    for i in range(numVal):\n",
    "        trainX=[]; trainY=[]\n",
    "        testX = []; testY = []\n",
    "        random.shuffle(indexList)\n",
    "        for j in range(m):#create training set based on first 90% of values in indexList\n",
    "            if j < m*0.9: \n",
    "                trainX.append(xArr[indexList[j]])\n",
    "                trainY.append(yArr[indexList[j]])\n",
    "            else:\n",
    "                testX.append(xArr[indexList[j]])\n",
    "                testY.append(yArr[indexList[j]])\n",
    "        wMat = ridgeTest(trainX,trainY)    #get 30 weight vectors from ridge\n",
    "        for k in range(30):#loop over all of the ridge estimates\n",
    "            matTestX = mat(testX); matTrainX=mat(trainX)\n",
    "            meanTrain = mean(matTrainX,0)\n",
    "            varTrain = var(matTrainX,0)\n",
    "            matTestX = (matTestX-meanTrain)/varTrain #regularize test with training params\n",
    "            yEst = matTestX * mat(wMat[k,:]).T + mean(trainY)#test ridge results and store\n",
    "            errorMat[i,k]=rssError(yEst.T.A,array(testY))\n",
    "            #print errorMat[i,k]\n",
    "    meanErrors = mean(errorMat,0)#calc avg performance of the different ridge weight vectors\n",
    "    minMean = float(min(meanErrors))\n",
    "    bestWeights = wMat[nonzero(meanErrors==minMean)]\n",
    "    #can unregularize to get model\n",
    "    #when we regularized we wrote Xreg = (x-meanX)/var(x)\n",
    "    #we can now write in terms of x not Xreg:  x*w/var(x) - meanX/var(x) +meanY\n",
    "    xMat = mat(xArr); yMat=mat(yArr).T\n",
    "    meanX = mean(xMat,0); varX = var(xMat,0)\n",
    "    unReg = bestWeights/varX\n",
    "    print(\"the best model from Ridge Regression is:\\n\",unReg)\n",
    "    print(\"with constant term: \",-1*sum(multiply(meanX,unReg)) + mean(yMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best model from Ridge Regression is:\n",
      " [[  0.0662818   -2.16040657  14.80838471  10.57654272   9.63189893\n",
      "  -20.59981927 -10.00037865   7.99808439]]\n",
      "with constant term:  2.862909551269757\n"
     ]
    }
   ],
   "source": [
    "regression3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图绘制除了回归系数与 log(λ) 的关系。在最左边，即 λ 最小时，可以得到所有系数的原始值（与线性回归一致）；而在右边，系数全部缩减为0；在中间部分的某值将可以取得最好的预测效果。为了定量地找到最佳参数值，还需要进行交叉验证。另外，要判断哪些变量对结果预测最具有影响力，在上图中观察它们对应的系数大小就可以了。\n",
    "\n",
    "## lasso\n",
    "\n",
    "在增加如下约束时，普通的最小二乘法回归会得到与岭回归一样的公式:\n",
    "$$\n",
    "\\sum_{k=1}^{n} w_k ^2 \\leq \\lambda\n",
    "$$\n",
    "\n",
    "上式限定了所有回归系数的平方和不能大于 λ 。使用普通的最小二乘法回归在当两个或更多的特征相关时，可能会得到一个很大的正系数和一个很大的负系数。正式因为上述限制条件的存在，使用岭回归可以避免这个问题。\n",
    "\n",
    "与岭回归类似，另一个缩减方法lasso也对回归系数做了限定，对应的约束条件如下:\n",
    "$$\n",
    "\\sum_{k=1}^{n} |w_k| \\leq \\lambda\n",
    "$$\n",
    "唯一的不同点在于，这个约束条件使用绝对值取代了平方和。虽然约束形式只是稍作变化，结果却大相径庭: 在 λ 足够小的时候，一些系数会因此被迫缩减到 0.这个特性可以帮助我们更好地理解数据。\n",
    "\n",
    "\n",
    "## 前向逐步回归\n",
    "\n",
    "前向逐步回归算法可以得到与 lasso 差不多的效果，但更加简单。它属于一种贪心算法，即每一步都尽可能减少误差。一开始，所有权重都设置为 1，然后每一步所做的决策是对某个权重增加或减少一个很小的值。\n",
    "\n",
    "伪代码如下:\n",
    "```\n",
    "数据标准化，使其分布满足 0 均值 和单位方差\n",
    "在每轮迭代过程中: \n",
    "    设置当前最小误差 lowestError 为正无穷\n",
    "    对每个特征:\n",
    "        增大或缩小:\n",
    "            改变一个系数得到一个新的 w\n",
    "            计算新 w 下的误差\n",
    "            如果误差 Error 小于当前最小误差 lowestError: 设置 Wbest 等于当前的 W\n",
    "        将 W 设置为新的 Wbest\n",
    "```      \n",
    "\n",
    "\n",
    "### 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#逐步线性回归算法\n",
    "# eps为每次迭代需要调整的步长，numIt为迭代次数\n",
    "def stageWise(xArr,yArr,eps=0.01,numIt=100):\n",
    "    xMat=mat(xArr);yMat=mat(yArr).T\n",
    "    # 标准化处理\n",
    "    yMean=mean(yMat,0)\n",
    "    yMat=yMat-yMean\n",
    "    xMat=regularize(xMat)\n",
    "    m,n=shape(xMat)\n",
    "    returnMat=zeros((numIt,n))\n",
    "    ws=zeros((n,1));wsTest=ws.copy();wsMax=ws.copy()\n",
    "    # 每一次迭代\n",
    "    for i in range(numIt):\n",
    "        # 打印出这次的系数\n",
    "        print(ws.T)\n",
    "        lowestError=inf\n",
    "        # 对每一个特征\n",
    "        for j in range(n):\n",
    "            for sign in [-1,1]:\n",
    "                wsTest=ws.copy()\n",
    "                wsTest[j]+=eps*sign\n",
    "                yTest=xMat*wsTest\n",
    "                rssE=rssError(yMat.A,yTest.A)\n",
    "                if(rssE<lowestError):\n",
    "                    lowestError=rssE\n",
    "                    wsMax=wsTest\n",
    "        ws=wsMax.copy()\n",
    "        returnMat[i,:]=ws.T\n",
    "    return returnMat\n",
    "\n",
    "\n",
    "\n",
    "#test for stageWise\n",
    "def regression4():\n",
    "    xArr,yArr=loadDataSet(\"./input&code/Ch08/abalone.txt\")\n",
    "    stageWise(xArr,yArr,0.01,200)\n",
    "    xMat = mat(xArr)\n",
    "    yMat = mat(yArr).T\n",
    "    xMat = regularize(xMat)\n",
    "    yM = mean(yMat,0)\n",
    "    yMat = yMat - yM\n",
    "    weights = standRegress(xMat, yMat.T)\n",
    "    print (weights.T)\n",
    "    \n",
    "def rssError(yArr,yHatArr):  \n",
    "    return((yArr-yHatArr)**2).sum()  \n",
    "\n",
    "def regularize(xMat):  \n",
    "    inMat=xMat.copy()  \n",
    "    inMeans=mean(inMat,0)   \n",
    "    inVar=var(inMat,0)\n",
    "    inMat=(inMat-inMeans)/inVar  \n",
    "    return inMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0.   0.   0.   0.01 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.   0.02 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.   0.03 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.   0.04 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.   0.05 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.   0.06 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.  ]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.01]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.02]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.03]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.04]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.05]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.06]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.07]]\n",
      "[[0.   0.   0.01 0.06 0.   0.   0.   0.08]]\n",
      "[[0.   0.   0.01 0.05 0.   0.   0.   0.08]]\n",
      "[[0.   0.   0.01 0.05 0.   0.   0.   0.09]]\n",
      "[[0.   0.   0.01 0.05 0.   0.   0.   0.1 ]]\n",
      "[[0.   0.   0.01 0.05 0.   0.   0.   0.11]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.01  0.    0.11]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.02  0.    0.11]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.02  0.    0.12]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.03  0.    0.12]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.03  0.    0.13]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.04  0.    0.13]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.05  0.    0.13]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.05  0.    0.14]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.06  0.    0.14]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.07  0.    0.14]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.07  0.    0.15]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.08  0.    0.15]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.08  0.    0.16]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.09  0.    0.16]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.1   0.    0.16]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.1   0.    0.17]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.11  0.    0.17]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.12  0.    0.17]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.12  0.    0.18]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.13  0.    0.18]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.13  0.    0.19]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.14  0.    0.19]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.15  0.    0.19]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.15  0.    0.2 ]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.16  0.    0.2 ]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.16  0.    0.21]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.17  0.    0.21]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.18  0.    0.21]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.18  0.    0.22]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.19  0.    0.22]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.2   0.    0.22]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.2   0.    0.23]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.21  0.    0.23]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.21  0.    0.24]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.22  0.    0.24]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.23  0.    0.24]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.23  0.    0.25]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.24  0.    0.25]]\n",
      "[[ 0.    0.    0.01  0.05  0.   -0.25  0.    0.25]]\n",
      "[[ 0.    0.    0.02  0.05  0.   -0.25  0.    0.25]]\n",
      "[[ 0.    0.    0.02  0.04  0.   -0.25  0.    0.25]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.25  0.    0.25]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.25  0.    0.26]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.26  0.    0.26]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.26  0.    0.27]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.27  0.    0.27]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.28  0.    0.27]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.28  0.    0.28]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.29  0.    0.28]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.29  0.    0.29]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.3   0.    0.29]]\n",
      "[[ 0.    0.    0.03  0.04  0.   -0.31  0.    0.29]]\n",
      "[[ 0.    0.    0.04  0.04  0.   -0.31  0.    0.29]]\n",
      "[[ 0.    0.    0.04  0.04  0.   -0.32  0.    0.29]]\n",
      "[[ 0.    0.    0.04  0.04  0.   -0.33  0.    0.29]]\n",
      "[[ 0.    0.    0.04  0.04  0.   -0.33  0.    0.3 ]]\n",
      "[[ 0.    0.    0.04  0.04  0.   -0.34  0.    0.3 ]]\n",
      "[[ 0.    0.    0.04  0.04  0.   -0.35  0.    0.3 ]]\n",
      "[[ 0.    0.    0.05  0.04  0.   -0.35  0.    0.3 ]]\n",
      "[[ 0.    0.    0.05  0.04  0.   -0.36  0.    0.3 ]]\n",
      "[[ 0.    0.    0.05  0.04  0.   -0.37  0.    0.3 ]]\n",
      "[[ 0.    0.    0.05  0.04  0.   -0.37  0.    0.31]]\n",
      "[[ 0.    0.    0.05  0.04  0.   -0.38  0.    0.31]]\n",
      "[[ 0.    0.    0.05  0.04  0.   -0.39  0.    0.31]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.39  0.    0.31]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.4   0.    0.31]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.41  0.    0.31]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.41  0.    0.32]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.42  0.    0.32]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.42  0.    0.33]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.43  0.    0.33]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.44  0.    0.33]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.44  0.    0.34]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.45  0.    0.34]]\n",
      "[[ 0.    0.    0.06  0.04  0.   -0.46  0.    0.34]]\n",
      "[[ 0.    0.    0.07  0.04  0.   -0.46  0.    0.34]]\n",
      "[[ 0.    0.    0.07  0.03  0.   -0.46  0.    0.34]]\n",
      "[[ 0.    0.    0.08  0.03  0.   -0.46  0.    0.34]]\n",
      "[[ 0.    0.    0.08  0.03  0.   -0.46  0.    0.35]]\n",
      "[[ 0.    0.    0.08  0.03  0.   -0.47  0.    0.35]]\n",
      "[[ 0.    0.    0.08  0.03  0.   -0.47  0.    0.36]]\n",
      "[[ 0.    0.    0.08  0.03  0.   -0.48  0.    0.36]]\n",
      "[[ 0.    0.    0.08  0.03  0.   -0.49  0.    0.36]]\n",
      "[[ 0.    0.    0.09  0.03  0.   -0.49  0.    0.36]]\n",
      "[[ 0.    0.    0.09  0.03  0.   -0.5   0.    0.36]]\n",
      "[[ 0.    0.    0.09  0.03  0.   -0.51  0.    0.36]]\n",
      "[[ 0.    0.    0.09  0.03  0.   -0.51  0.    0.37]]\n",
      "[[ 0.    0.    0.09  0.03  0.   -0.52  0.    0.37]]\n",
      "[[ 0.    0.    0.09  0.03  0.01 -0.52  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.01 -0.52  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.01 -0.53  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.02 -0.53  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.03 -0.53  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.04 -0.53  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.04 -0.54  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.05 -0.54  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.06 -0.54  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.06 -0.55  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.07 -0.55  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.08 -0.55  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.08 -0.56  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.09 -0.56  0.    0.37]]\n",
      "[[ 0.01  0.    0.09  0.03  0.1  -0.56  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.1  -0.56  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.1  -0.57  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.11 -0.57  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.12 -0.57  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.13 -0.57  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.13 -0.58  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.14 -0.58  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.15 -0.58  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.15 -0.59  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.16 -0.59  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.17 -0.59  0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.17 -0.6   0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.18 -0.6   0.    0.37]]\n",
      "[[ 0.02  0.    0.09  0.03  0.19 -0.6   0.    0.37]]\n",
      "[[ 0.03  0.    0.09  0.03  0.19 -0.6   0.    0.37]]\n",
      "[[ 0.03  0.    0.09  0.03  0.19 -0.61  0.    0.37]]\n",
      "[[ 0.03  0.    0.09  0.03  0.2  -0.61  0.    0.37]]\n",
      "[[ 0.03  0.    0.09  0.03  0.21 -0.61  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.21 -0.61  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.22 -0.61  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.22 -0.62  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.23 -0.62  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.24 -0.62  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.24 -0.63  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.25 -0.63  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.26 -0.63  0.    0.37]]\n",
      "[[ 0.04  0.    0.09  0.03  0.26 -0.63  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.27 -0.63  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.28 -0.63  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.29 -0.63  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.29 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.3  -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.05  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.04  0.    0.09  0.03  0.31 -0.64  0.    0.36]]\n",
      "[[ 0.0430442  -0.02274163  0.13214087  0.02075182  2.22403814 -0.99895312\n",
      "  -0.11725427  0.16622915]]\n"
     ]
    }
   ],
   "source": [
    "regression4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./image/第8章回归/6.jpg)\n",
    "\n",
    "逐步线性回归算法的主要优点在于它可以帮助人们理解现有的模型并作出改进。当构建了一个模型后，可以运行该算法找出重要的特征，这样就有可能及时停止对那些不重要特征的手机。最后，如果用于测试，该算法每100次迭代后就可以构建出一个模型，可以使用类似于10折交叉验证的方法比较这些模型，最终选择使误差最小的模型。\n",
    "\n",
    "### 小结\n",
    "当应用缩减方法（如逐步线性回归或岭回归）时，模型也就增加了偏差（bias），与此同时却减小了模型的方差。\n",
    "\n",
    "\n",
    "## 权衡偏差和方差\n",
    "任何时候，一旦发现模型和测量值之间存在差异，就说出现了误差。当考虑模型中的 “噪声” 或者说误差时，必须考虑其来源。你可能会对复杂的过程进行简化，这将导致在模型和测量值之间出现 “噪声” 或误差，若无法理解数据的真实生成过程，也会导致差异的产生。另外，测量过程本身也可能产生 “噪声” 或者问题。下面我们举一个例子，我们使用 线性回归 和 局部加权线性回归 处理过一个从文件导入的二维数据。\n",
    "\n",
    "$$\n",
    "y=3.0+1.7x+0.1\\sin (30x)+0.06N(0,1)\n",
    "$$\n",
    "\n",
    "其中的 N(0, 1) 是一个均值为 0、方差为 1 的正态分布。我们尝试过禁用一条直线来拟合上述数据。不难想到，直线所能得到的最佳拟合应该是 3.0+1.7x 这一部分。这样的话，误差部分就是 0.1sin(30x)+0.06N(0, 1) 。在上面，我们使用了局部加权线性回归来试图捕捉数据背后的结构。该结构拟合起来有一定的难度，因此我们测试了多组不同的局部权重来找到具有最小测试误差的解。\n",
    "\n",
    "下图给出了训练误差和测试误差的曲线图，上面的曲面就是测试误差，下面的曲线是训练误差。我们根据 预测鲍鱼年龄 的实验知道: 如果降低核的大小，那么训练误差将变小。从下图开看，从左到右就表示了核逐渐减小的过程。\n",
    "\n",
    "![](./image/第8章回归/7.jpg)\n",
    "\n",
    "一般认为，上述两种误差由三个部分组成: 偏差、测量误差和随机噪声。局部加权线性回归 和 预测鲍鱼年龄 中，我们通过引入了三个越来越小的核来不断增大模型的方差。\n",
    "\n",
    "在缩减系数来“理解”数据这一节中，我们介绍了缩减法，可以将一些系数缩减成很小的值或直接缩减为 0 ，这是一个增大模型偏差的例子。通过把一些特征的回归系数缩减到 0 ，同时也就减小了模型的复杂度。例子中有 8 个特征，消除其中两个后不仅使模型更易理解，同时还降低了预测误差。对照上图，左侧是参数缩减过于严厉的结果，而右侧是无缩减的效果。\n",
    "\n",
    "方差是可以度量的。如果从鲍鱼数据中取一个随机样本集（例如取其中 100 个数据）并用线性模型拟合，将会得到一组回归系数。同理，再取出另一组随机样本集并拟合，将会得到另一组回归系数。这些系数间的差异大小也就是模型方差的反映。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 项目案例1: 预测乐高玩具套装的价格\n",
    "**项目概述**\n",
    "Dangler 喜欢为乐高套装估价，我们用回归技术来帮助他建立一个预测模型。\n",
    "\n",
    "开发流程\n",
    ">(1) 收集数据：用 Google Shopping 的API收集数据。\n",
    "(2) 准备数据：从返回的JSON数据中抽取价格。\n",
    "(3) 分析数据：可视化并观察数据。\n",
    "(4) 训练算法：构建不同的模型，采用逐步线性回归和直接的线性回归模型。\n",
    "(5) 测试算法：使用交叉验证来测试不同的模型，分析哪个效果最好。\n",
    "(6) 使用算法：这次练习的目标就是生成数据模型。\n",
    "\n",
    ">收集数据: 使用 Google 购物的 API\n",
    "\n",
    "由于 Google 提供的 api 失效，我们只能自己下载咯，将数据存储在了 input 文件夹下的 setHtml 文件夹下\n",
    "\n",
    ">准备数据: 从返回的 JSON 数据中抽取价格\n",
    "\n",
    "因为我们这里不是在线的，就不再是 JSON 了，我们直接解析线下的网页，得到我们想要的数据。\n",
    "\n",
    ">分析数据: 可视化并观察数据\n",
    "\n",
    "这里我们将解析得到的数据打印出来，然后观察数据。\n",
    "\n",
    ">训练算法: 构建不同的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 从页面读取数据，生成retX和retY列表\n",
    "def scrapePage(retX, retY, inFile, yr, numPce, origPrc):\n",
    "\n",
    "    # 打开并读取HTML文件\n",
    "    fr = open(inFile,encoding='gb18030', errors='ignore')\n",
    "    soup = BeautifulSoup(fr.read(),\"lxml\")\n",
    "    i=1\n",
    "\n",
    "    # 根据HTML页面结构进行解析\n",
    "    currentRow = soup.findAll('table', r=\"%d\" % i)\n",
    "    while(len(currentRow)!=0):\n",
    "        currentRow = soup.findAll('table', r=\"%d\" % i)\n",
    "        title = currentRow[0].findAll('a')[1].text\n",
    "        lwrTitle = title.lower()\n",
    "\n",
    "        # 查找是否有全新标签\n",
    "        if (lwrTitle.find('new') > -1) or (lwrTitle.find('nisb') > -1):\n",
    "            newFlag = 1.0\n",
    "        else:\n",
    "            newFlag = 0.0\n",
    "\n",
    "        # 查找是否已经标志出售，我们只收集已出售的数据\n",
    "        soldUnicde = currentRow[0].findAll('td')[3].findAll('span')\n",
    "        if len(soldUnicde)==0:\n",
    "            print(\"item #%d did not sell\" % i)\n",
    "        else:\n",
    "            # 解析页面获取当前价格\n",
    "            soldPrice = currentRow[0].findAll('td')[4]\n",
    "            priceStr = soldPrice.text\n",
    "            priceStr = priceStr.replace('$','') #strips out $\n",
    "            priceStr = priceStr.replace(',','') #strips out ,\n",
    "            if len(soldPrice)>1:\n",
    "                priceStr = priceStr.replace('Free shipping', '')\n",
    "            sellingPrice = float(priceStr)\n",
    "\n",
    "            # 去掉不完整的套装价格\n",
    "            if  sellingPrice > origPrc * 0.5:\n",
    "                    print(\"%d\\t%d\\t%d\\t%f\\t%f\" % (yr,numPce,newFlag,origPrc, sellingPrice))\n",
    "                    retX.append([yr, numPce, newFlag, origPrc])\n",
    "                    retY.append(sellingPrice)\n",
    "        i += 1\n",
    "        currentRow = soup.findAll('table', r=\"%d\" % i)\n",
    "\n",
    "# 依次读取六种乐高套装的数据，并生成数据矩阵        \n",
    "def setDataCollect(retX, retY):\n",
    "    scrapePage(retX, retY, './input&code/Ch08/setHtml/lego8288.html', 2006, 800, 49.99)\n",
    "    scrapePage(retX, retY, './input&code/Ch08/setHtml/lego10030.html', 2002, 3096, 269.99)\n",
    "    scrapePage(retX, retY, './input&code/Ch08/setHtml/lego10179.html', 2007, 5195, 499.99)\n",
    "    scrapePage(retX, retY, './input&code/Ch08/setHtml/lego10181.html', 2007, 3428, 199.99)\n",
    "    scrapePage(retX, retY, './input&code/Ch08/setHtml/lego10189.html', 2008, 5922, 299.99)\n",
    "    scrapePage(retX, retY, './input&code/Ch08/setHtml/lego10196.html', 2009, 3263, 249.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">测试算法：使用交叉验证来测试不同的模型，分析哪个效果最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for lego's price\n",
    "def regression5():\n",
    "    lgX = []\n",
    "    lgY = []\n",
    "\n",
    "    setDataCollect(lgX, lgY)\n",
    "    crossValidation(lgX, lgY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\t800\t0\t49.990000\t85.000000\n",
      "2006\t800\t0\t49.990000\t102.500000\n",
      "2006\t800\t0\t49.990000\t77.000000\n",
      "item #4 did not sell\n",
      "2006\t800\t0\t49.990000\t162.500000\n",
      "2002\t3096\t0\t269.990000\t699.990000\n",
      "2002\t3096\t0\t269.990000\t602.000000\n",
      "2002\t3096\t0\t269.990000\t515.000000\n",
      "2002\t3096\t0\t269.990000\t510.000000\n",
      "2002\t3096\t0\t269.990000\t375.000000\n",
      "2002\t3096\t1\t269.990000\t1050.000000\n",
      "2002\t3096\t0\t269.990000\t740.000000\n",
      "2002\t3096\t1\t269.990000\t759.000000\n",
      "2002\t3096\t0\t269.990000\t730.000000\n",
      "2002\t3096\t1\t269.990000\t750.000000\n",
      "item #11 did not sell\n",
      "2007\t5195\t0\t499.990000\t910.000000\n",
      "2007\t5195\t1\t499.990000\t1199.990000\n",
      "2007\t5195\t0\t499.990000\t811.880000\n",
      "item #4 did not sell\n",
      "2007\t5195\t0\t499.990000\t1324.790000\n",
      "2007\t5195\t1\t499.990000\t850.000000\n",
      "2007\t5195\t1\t499.990000\t800.000000\n",
      "2007\t5195\t0\t499.990000\t810.000000\n",
      "2007\t5195\t1\t499.990000\t1075.000000\n",
      "2007\t5195\t0\t499.990000\t1050.000000\n",
      "2007\t5195\t1\t499.990000\t1199.990000\n",
      "2007\t5195\t0\t499.990000\t1342.310000\n",
      "2007\t5195\t1\t499.990000\t1000.000000\n",
      "2007\t5195\t0\t499.990000\t1780.000000\n",
      "2007\t5195\t0\t499.990000\t750.000000\n",
      "item #16 did not sell\n",
      "2007\t5195\t0\t499.990000\t2204.990000\n",
      "item #18 did not sell\n",
      "2007\t5195\t1\t499.990000\t925.000000\n",
      "2007\t5195\t0\t499.990000\t860.000000\n",
      "item #21 did not sell\n",
      "item #22 did not sell\n",
      "2007\t5195\t1\t499.990000\t1199.990000\n",
      "2007\t5195\t1\t499.990000\t1099.990000\n",
      "2007\t5195\t1\t499.990000\t1149.990000\n",
      "2007\t5195\t1\t499.990000\t800.000000\n",
      "2007\t5195\t1\t499.990000\t850.000000\n",
      "2007\t3428\t0\t199.990000\t469.950000\n",
      "2007\t3428\t0\t199.990000\t479.000000\n",
      "2007\t3428\t0\t199.990000\t299.990000\n",
      "2007\t3428\t0\t199.990000\t369.000000\n",
      "2007\t3428\t1\t199.990000\t424.950000\n",
      "2007\t3428\t1\t199.990000\t380.000000\n",
      "2007\t3428\t0\t199.990000\t305.000000\n",
      "2008\t5922\t1\t299.990000\t530.000000\n",
      "item #2 did not sell\n",
      "2008\t5922\t1\t299.990000\t599.950000\n",
      "2008\t5922\t0\t299.990000\t510.000000\n",
      "2008\t5922\t0\t299.990000\t423.000000\n",
      "item #6 did not sell\n",
      "item #7 did not sell\n",
      "2008\t5922\t1\t299.990000\t599.990000\n",
      "item #9 did not sell\n",
      "2008\t5922\t1\t299.990000\t589.990000\n",
      "2008\t5922\t1\t299.990000\t569.990000\n",
      "2008\t5922\t1\t299.990000\t529.990000\n",
      "2008\t5922\t0\t299.990000\t500.000000\n",
      "2008\t5922\t1\t299.990000\t549.950000\n",
      "2008\t5922\t0\t299.990000\t300.000000\n",
      "item #16 did not sell\n",
      "2009\t3263\t1\t249.990000\t380.000000\n",
      "2009\t3263\t1\t249.990000\t399.000000\n",
      "2009\t3263\t1\t249.990000\t427.990000\n",
      "2009\t3263\t0\t249.990000\t360.000000\n",
      "item #5 did not sell\n",
      "item #6 did not sell\n",
      "2009\t3263\t1\t249.990000\t399.000000\n",
      "2009\t3263\t1\t249.990000\t399.950000\n",
      "2009\t3263\t1\t249.990000\t499.990000\n",
      "item #10 did not sell\n",
      "2009\t3263\t0\t249.990000\t399.950000\n",
      "item #12 did not sell\n",
      "2009\t3263\t1\t249.990000\t331.510000\n",
      "the best model from Ridge Regression is:\n",
      " [[-2.29483500e+01  1.00363637e-03  2.36629544e+00  1.93393101e+00]]\n",
      "with constant term:  46088.19259412893\n"
     ]
    }
   ],
   "source": [
    "regression5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
